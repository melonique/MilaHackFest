{"cells":[{"cell_type":"markdown","id":"af2d1047d1a8477c","metadata":{"id":"af2d1047d1a8477c"},"source":["# Introduction to Machine Learning through a PyTorch Tutorial\n","\n","By Philippe, mentor on the Quandela team\n","\n","## Introduction\n","\n","PyTorch is an open source library for machine learning that is often used in research to define deep learning models and train them efficiently. Some alternatives to PyTorch are [TensorFlow](https://www.tensorflow.org) and [JAX](https://docs.jax.dev/en/latest/notebooks/thinking_in_jax.html). There are many PyTorch tutorials out there, so feel free to explore. Namely, there are many tutorials produced by the PyTorch team [here](https://docs.pytorch.org/tutorials/) and the inspiration for this current tutorial comes from the University of Amsterdam: [here](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.html) is a notebook authored by Philippe Lippe.\n","\n","As a prerequisite for this tutorial, you should have some knowledge of Numpy. If that is not the case, we recommend you follow a Numpy tutorial like [this one](https://numpy.org/doc/stable/user/quickstart.html) beforehand.\n","\n","### Why is it so important to know how to use PyTorch ?\n","\n","#### In the context of classical machine learning:\n","PyTorch stands as a predominant tool because of its high efficiency, simple usage and high customizability which enables researchers to experiment however they want with a performing framework.\n","\n","1. **Automatic differentiation**\n","\n","PyTorch builds a computational graph that handles backpropagation for gradient descent automatically and that is very useful for optimizing models.\n","\n","2. **GPU acceleration**\n","\n","PyTorch has integrated many features to effortlessly use GPUs, making large-scale training feasible.\n","\n","3. **Modular neural network building blocks**\n","\n","This library provides customizable building blocks to assemble flexible models which ease prototyping and exploration.\n","\n","4. **Ecosystem**\n","\n","PyTorch is well established in the machine learning ecosystem so many people use it for several goals. Its popularity also justifies its importance.\n","\n","#### In the context of quantum machine learning:\n","PyTorch is a wonderful tool too since its well known optimization engine can be used for quantum circuits in most cases, it allows for research prototyping with quantum/hybrid models and it is integrated into many quantum computing frameworks.\n","\n","1. **Quantum-classical workflow**\n","\n","The partition of work between PyTorch and the quantum computing libraries is straightforward. PyTorch handles the optimization whereas the quantum circuit simulator/hardware provides the forward pass (direct computation). Computing gradients of quantum circuits is a complex task, but with a QML library wrapped with PyTorch's autograd, the code to train a quantum model is the same as the one to train a classical model.\n","\n","2. **Integration with quantum frameworks**\n","\n","Libraries like [Pennylane](https://docs.pennylane.ai/en/stable/), [Merlin](https://merlinquantum.ai), [TorchQuantum](https://torchquantum.readthedocs.io/en/main/) or [Qiskit Machine Learning](https://qiskit-community.github.io/qiskit-machine-learning/) integrate with PyTorch.\n","\n","### Imports\n","We will use a set of standard libraries that are popular in machine learning."]},{"cell_type":"code","execution_count":null,"id":"2137c6f075339c04","metadata":{"ExecuteTime":{"end_time":"2025-09-29T15:23:31.230684Z","start_time":"2025-09-29T15:23:23.179362Z"},"id":"2137c6f075339c04"},"outputs":[],"source":["import os\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import time\n","import torch\n","from tqdm.notebook import tqdm"]},{"cell_type":"markdown","id":"cdb5e71215cf9b81","metadata":{"id":"cdb5e71215cf9b81"},"source":["The PyTorch library was imported by calling `import torch`. Let's check its version:"]},{"cell_type":"code","execution_count":null,"id":"d118771fb86fbedc","metadata":{"ExecuteTime":{"end_time":"2025-09-29T15:28:33.591305Z","start_time":"2025-09-29T15:28:33.589096Z"},"id":"d118771fb86fbedc","outputId":"0efa5c27-48b3-4c9d-e163-1c36238b74ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using torch 2.8.0\n"]}],"source":["print(f'Using torch {torch.__version__}')"]},{"cell_type":"markdown","id":"c73a445f1d1e44c0","metadata":{"id":"c73a445f1d1e44c0"},"source":["As soon as you run the previous cell you will see the exact version installed in your environment. These examples target PyTorch 2.x, so a nearby version should work without changes. If you ever need to install a different release, run `pip install torch==<desired version>` before the import block and restart the notebook kernel to load it."]},{"cell_type":"code","execution_count":null,"id":"93ef3086578cd482","metadata":{"ExecuteTime":{"end_time":"2025-09-29T15:38:24.891595Z","start_time":"2025-09-29T15:38:24.883669Z"},"id":"93ef3086578cd482","outputId":"908e973c-929a-4889-c4fd-e95dc2dfd3e9"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x10f3101d0>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(42)"]},{"cell_type":"markdown","id":"bc5f7309aa7caa9","metadata":{"id":"bc5f7309aa7caa9"},"source":["## Tensors\n","\n","Tensors are the foundational tools of PyTorch. They are equivalent to Numpy arrays, but they support automatic backpropagation and have support for GPU acceleration. A tensor has a certain number of dimensions. A vector would be represented by a 1-D tensor and a matrix would be represented by a 2-D tensor. Each dimension of a tensor has a size that indicates the number of elements present in the tensor along the respective dimension. Furthermore, the shape of a tensor is the size of each of its dimensions. For example:\n","\n","tensor[[1, 2],\n","       [3, 4],\n","       [5, 6]]\n","\n","would have a shape of (3, 2) because it has 3 rows (first dimension) and 2 columns (second dimension). And a tensor with shape (1, 3, 5) would have a first dimension of size 1, a second dimension of size 3 and a third dimension of size 5.\n","\n","### Tensor Initialization\n","There are many ways to initialize a tensor but the simplest is to call `torch.tensor({array})` which converts the input array into a tensor:"]},{"cell_type":"code","execution_count":null,"id":"a1e652119127eea5","metadata":{"ExecuteTime":{"end_time":"2025-09-29T16:02:28.453420Z","start_time":"2025-09-29T16:02:28.450796Z"},"id":"a1e652119127eea5","outputId":"e579ba6c-1ee5-4104-aca3-510d5df7e05a"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 3, 5])\n"]}],"source":["x = torch.tensor([1, 3, 5])\n","print(x)"]},{"cell_type":"markdown","id":"801d72e0ebbde749","metadata":{"id":"801d72e0ebbde749"},"source":["Other methods for initialization include:\n","- `torch.zeros({shape})`: Creates a tensor filled with zeros of shape {shape}\n","- `torch.ones({shape})`: Creates a tensor filled with ones of shape {shape}\n","- `torch.rand({shape})`: Creates a tensor of shape {shape} filled with random values uniformly sampled between 0 and 1\n","- `torch.arange({N}, {M+1})`: Creates a 1-D tensor containing the values N, N+1, N+2, ... M"]},{"cell_type":"code","execution_count":null,"id":"505804314c6bd687","metadata":{"ExecuteTime":{"end_time":"2025-09-29T16:09:37.570789Z","start_time":"2025-09-29T16:09:37.565456Z"},"id":"505804314c6bd687","outputId":"ec26308f-ecf9-4986-fb4d-69893d355a77"},"outputs":[{"name":"stdout","output_type":"stream","text":["- torch.zeros((2, 3)):\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","- torch.ones((3, 2)):\n","tensor([[1., 1.],\n","        [1., 1.],\n","        [1., 1.]])\n","- torch.rand((3, 3)):\n","tensor([[0.8823, 0.9150, 0.3829],\n","        [0.9593, 0.3904, 0.6009],\n","        [0.2566, 0.7936, 0.9408]])\n","- torch.aragne(10, 15):\n","tensor([10, 11, 12, 13, 14])\n"]}],"source":["x_1 = torch.zeros((2, 3))\n","print(f'- torch.zeros((2, 3)):\\n{x_1}')\n","x_2 = torch.ones((3, 2))\n","print(f'- torch.ones((3, 2)):\\n{x_2}')\n","x_3 = torch.rand((3, 3))\n","print(f'- torch.rand((3, 3)):\\n{x_3}')\n","x_4 = torch.arange(10, 15)\n","print(f'- torch.aragne(10, 15):\\n{x_4}')"]},{"cell_type":"markdown","id":"8e9fba40692aa95d","metadata":{"id":"8e9fba40692aa95d"},"source":["Note that it is not always necessary to use a second pair of parenthesis when defining the shape for these methods:"]},{"cell_type":"code","execution_count":null,"id":"99b944924f0f7938","metadata":{"ExecuteTime":{"end_time":"2025-09-29T16:14:50.913573Z","start_time":"2025-09-29T16:14:50.910437Z"},"id":"99b944924f0f7938","outputId":"681eae88-55ff-4ee2-845f-254a9deb8b4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"]}],"source":["x_5 =  torch.zeros(2, 3)\n","print(x_5)"]},{"cell_type":"markdown","id":"9d1a3784aa149e0e","metadata":{"id":"9d1a3784aa149e0e"},"source":["The shape of a tensor is its most important characteristic because most operations between tensors require that they share a common size within their shape. For simple examples, we can look at matrix operations as a parallel:\n","\n","1. Matrix addition ($M_1 + M_2$) requires that $M_1$ and $M_2$ have the same shape.\n","2. Matrix product ($M_1 \\cdot M_2$) requires that the second dimension of $M_1$ is equal to the first dimension of $M_2$.\n","\n","Moreover, you can obtain the shape of a tensor by simply using `.shape` or `.size()` on a tensor:"]},{"cell_type":"code","execution_count":null,"id":"b68b59bd2c37f5d","metadata":{"ExecuteTime":{"end_time":"2025-09-29T16:27:42.079822Z","start_time":"2025-09-29T16:27:42.077673Z"},"id":"b68b59bd2c37f5d","outputId":"add59289-c7cf-4ad4-a4c1-4d43dda802d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 3])\n","torch.Size([3, 2])\n"]}],"source":["x_1_shape = x_1.shape\n","print(x_1_shape)\n","x_2_size = x_2.size()\n","print(x_2_size)"]},{"cell_type":"markdown","id":"468336dec63d565b","metadata":{"id":"468336dec63d565b"},"source":["### Tensor to Numpy and Numpy to Tensor\n","\n","Most functions you know from Numpy that can be applied to arrays also exist for tensors. Additionally, it is possible to convert Numpy arrays to tensors via `torch.tensor({Numpy array})` and vice versa using `tensor.numpy()`. The `.detach().cpu()` present below is a safeguard to ensure that the conversion works, but we will explain it later."]},{"cell_type":"code","execution_count":null,"id":"c1acfb810c256875","metadata":{"ExecuteTime":{"end_time":"2025-09-29T16:32:02.314098Z","start_time":"2025-09-29T16:32:02.311383Z"},"id":"c1acfb810c256875","outputId":"a54a27e8-810f-44f9-be45-d8125dad3ba7"},"outputs":[{"name":"stdout","output_type":"stream","text":["- Numpy array: [1 2 3 4]\n","- Tensor: tensor([1, 2, 3, 4])\n","- New Numpy array: [1 2 3 4]\n"]}],"source":["np_array = np.array([1, 2, 3, 4])\n","tensor = torch.tensor(np_array)\n","new_np_array = tensor.detach().cpu().numpy()\n","\n","print(f'- Numpy array: {np_array}')\n","print(f'- Tensor: {tensor}')\n","print(f'- New Numpy array: {new_np_array}')"]},{"cell_type":"markdown","id":"82de3b6e","metadata":{"id":"82de3b6e"},"source":["### Tensor Operations\n","\n","Any function that transforms a tensor or combines tensors is called an operation. We often chain operations to prepare data, clean features, or interpret model outputs.\n","\n","#### Unary Tensor Operations\n","\n","Unary operations take a single tensor as input. They usually reshape the data, cast it to another dtype, move it between devices, or apply an elementwise transformation.\n","\n","Some helpful shape utilities:\n","\n","- `tensor.reshape(new_shape)`: reshape a tensor to any compatible shape.\n","- `tensor.unsqueeze(dim)`: insert a dimension of size 1 at the given index.\n","- `tensor.squeeze(dim)`: remove a dimension if its size is 1.\n","- `tensor.permute(dims)`: reorder all dimensions at once.\n","- `tensor.transpose(dim0, dim1)`: swap two dimensions.\n","- `tensor.flatten(start_dim=0)`: merge dimensions into a single 1-D dimension.\n","- `tensor.repeat(*sizes)`: tile the tensor along specified dimensions.\n","\n","Dimensions in PyTorch are zero-indexed: `dim=0` refers to the first dimension (often rows), `dim=1` to the second (often columns), and so on. The meaning of each dimension depends on the tensor: in an image tensor shaped `(batch, channels, height, width)`, for instance, `dim=2` would correspond to the height dimension.\n","\n","Type and device helpers:\n","\n","- `tensor.to(device_or_dtype)`: move the tensor to a device or cast its dtype.\n","- `tensor.cpu()` / `tensor.cuda()`: explicit device moves between CPU and GPU.\n","- `tensor.clone()`: copy the tensor while keeping the original intact.\n","- `tensor.detach()`: get a tensor that shares storage but is disconnected from autograd.\n","\n","A **device** tells PyTorch where the tensor's data lives (CPU vs. GPU), while a **dtype** specifies the data type of the elements (e.g., `torch.float32`, `torch.int64`). Choosing the right device enables hardware acceleration, and choosing the right dtype balances precision and memory usage.\n","\n","Elementwise math and reductions:\n","\n","- `tensor.abs()`, `tensor.exp()`, `tensor.sqrt()`: apply functions to each value.\n","- `tensor.mean()`, `tensor.sum()`, `tensor.max()`: summarise values across dimensions.\n","- `tensor.norm()`: compute vector or matrix norms.\n","\n","These building blocks cover most shape and value manipulations you will need before stepping into multi-tensor operations."]},{"cell_type":"code","execution_count":null,"id":"eaa0211d","metadata":{"id":"eaa0211d","outputId":"5020e77f-407a-4506-d4a1-150d7cd05571"},"outputs":[{"name":"stdout","output_type":"stream","text":["- Original tensor of shape: torch.Size([2, 3]) \n"," tensor([[0, 1, 2],\n","        [3, 4, 5]])\n","- Reshaped to 3x2:\n"," tensor([[0, 1],\n","        [2, 3],\n","        [4, 5]])\n","- Unsqueezed shape:\n"," torch.Size([1, 2, 3]) \n","Unsqueezed tensor:\n"," tensor([[[0, 1, 2],\n","         [3, 4, 5]]])\n","- Squeezed back shape:\n"," torch.Size([2, 3])\n","- Transposed tensor:\n"," tensor([[0, 3],\n","        [1, 4],\n","        [2, 5]])\n","- Flattened tensor:\n"," tensor([0, 1, 2, 3, 4, 5])\n","- Casted to float dtype: torch.float32\n","- Clone shares values with original: True\n","- Absolute value example:\n"," tensor([2.0000, 0.0000, 3.5000])\n"]}],"source":["tensor = torch.arange(6).reshape(2, 3)\n","print('- Original tensor of shape:', tensor.shape, '\\n', tensor)\n","\n","reshaped = tensor.reshape(3, 2)\n","print('- Reshaped to 3x2:\\n', reshaped)\n","\n","unsqueezed = tensor.unsqueeze(0)\n","print('- Unsqueezed shape:\\n', unsqueezed.shape, '\\nUnsqueezed tensor:\\n', unsqueezed)\n","\n","squeezed = unsqueezed.squeeze(0)\n","print('- Squeezed back shape:\\n', squeezed.shape)\n","\n","transposed = tensor.transpose(0, 1)\n","print('- Transposed tensor:\\n', transposed)\n","\n","flattened = tensor.flatten()\n","print('- Flattened tensor:\\n', flattened)\n","\n","float_tensor = tensor.float()\n","print('- Casted to float dtype:', float_tensor.dtype)\n","\n","cloned = float_tensor.clone()\n","print('- Clone shares values with original:', torch.equal(float_tensor, cloned))\n","\n","absolute = torch.abs(torch.tensor([-2.0, 0.0, 3.5]))\n","print('- Absolute value example:\\n', absolute)"]},{"cell_type":"markdown","id":"bb50fb1f","metadata":{"id":"bb50fb1f"},"source":["#### Multiple Tensors Operations\n","\n","Operations can also take several tensors as inputs to combine or compare them.\n","\n","Elementwise arithmetic (`+`, `-`, `*`, `/` or `torch.add`) works when the tensors have the same shape or when broadcasting can align them. Matrix operations such as `torch.matmul` or the `@` operator (matrix multiplication) follow the familiar linear algebra rules. There are also utilities for concatenating or stacking tensors along a chosen dimension (`torch.cat`, `torch.stack`) and for comparisons (`torch.eq`, `torch.max`, etc.).\n","\n","**Broadcasting**\n","\n","Broadcasting automatically expands smaller tensors so that elementwise operations can run without copying data manually. PyTorch compares shapes from the last dimension backward and inserts size-1 dimensions when necessary. This is handy when, for instance, you add a bias vector to every row of a matrix."]},{"cell_type":"code","execution_count":null,"id":"16954142","metadata":{"id":"16954142","outputId":"30a918a5-d006-4423-d99b-4635eabaf4d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["- Elementwise addition:\n"," tensor([[11., 22., 33.],\n","        [44., 55., 66.]])\n","- Elementwise multiplication:\n"," tensor([[ 10.,  40.,  90.],\n","        [160., 250., 360.]])\n","- Matrix @ vector:\n"," tensor([2.5000, 5.5000])\n","- Broadcasted addition (matrix + vector):\n"," tensor([[1.5000, 3.0000],\n","        [3.5000, 5.0000]])\n","- Stacked vectors:\n"," tensor([[0.5000, 1.0000],\n","        [0.5000, 1.0000]])\n"]}],"source":["a = torch.tensor([[1., 2., 3.],\n","                  [4., 5., 6.]])\n","b = torch.tensor([[10., 20., 30.],\n","                  [40., 50., 60.]])\n","\n","print('- Elementwise addition:\\n', a + b)\n","print('- Elementwise multiplication:\\n', a * b)\n","\n","matrix = torch.tensor([[1., 2.], [3., 4.]])\n","vector = torch.tensor([0.5, 1.0])\n","print('- Matrix @ vector:\\n', matrix @ vector)\n","\n","print('- Broadcasted addition (matrix + vector):\\n', matrix + vector)\n","# Without broadcasting, this addition would fail because matrix.shape is not equal to vector.shape.\n","\n","stacked = torch.stack([vector, vector])\n","print('- Stacked vectors:\\n', stacked)"]},{"cell_type":"markdown","id":"58f97ec1","metadata":{"id":"58f97ec1"},"source":["### Indexing Tensors\n","\n","Indexing lets you read or write specific elements of a tensor. PyTorch adopts NumPy's slicing rules, so you can select rows, columns, or sub-blocks with `tensor[start:stop:step]`. Use commas to index multiple dimensions at once, ellipses (`...`) to skip middle dimensions, and integer or list indices for fancy indexing. Boolean masks (tensors of `True`/`False`) let you keep only the elements that satisfy a condition. Mastering indexing is key when you prepare batches or extract predictions."]},{"cell_type":"code","execution_count":null,"id":"a948bc75","metadata":{"id":"a948bc75","outputId":"2928ea37-e376-4a89-85d0-2a2f73b10630"},"outputs":[{"name":"stdout","output_type":"stream","text":["- Grid: tensor([[ 1,  2,  3,  4],\n","        [ 5,  6,  7,  8],\n","        [ 9, 10, 11, 12]])\n","- First row: tensor([1, 2, 3, 4])\n","- Last column: tensor([ 4,  8, 12])\n","- Center block: tensor([[ 6,  7],\n","        [10, 11]])\n","- Every other column: tensor([[ 1,  3],\n","        [ 5,  7],\n","        [ 9, 11]])\n","- Boolean mask: tensor([[False, False, False, False],\n","        [False, False,  True,  True],\n","        [ True,  True,  True,  True]])\n","- Values > 6: tensor([ 7,  8,  9, 10, 11, 12])\n"]}],"source":["grid = torch.arange(1, 13).reshape(3, 4)\n","print('- Grid:', grid)\n","\n","first_row = grid[0]\n","print('- First row:', first_row)\n","\n","last_column = grid[:, -1]\n","print('- Last column:', last_column)\n","\n","center_block = grid[1:, 1:3]\n","print('- Center block:', center_block)\n","\n","every_other = grid[:, ::2]\n","print('- Every other column:', every_other)\n","\n","mask = grid > 6\n","print('- Boolean mask:', mask)\n","print('- Values > 6:', grid[mask])"]},{"cell_type":"markdown","id":"8742fd24566d36c0","metadata":{"id":"8742fd24566d36c0"},"source":["## Dynamic Computation Graph and Backpropagation\n","\n","PyTorch builds a computation graph on the fly as you run operations. Each tensor can remember how it was created, and when `requires_grad=True`, PyTorch tracks the operations so that it can compute derivatives later.\n","\n","To compute gradients you call `.backward()` (usually on a scalar loss). PyTorch walks the graph in reverse (backpropagation) and fills the `.grad` attribute of leaf tensors (typically model parameters or inputs). If a tensor should participate in gradient computation, set `tensor.requires_grad_()` or create it with `requires_grad=True`. When you are finished using the gradients, make sure to reset them with `tensor.grad.zero_()` or `optimizer.zero_grad()` to avoid accidental accumulation."]},{"cell_type":"code","execution_count":null,"id":"4c2458b7","metadata":{"id":"4c2458b7","outputId":"2932ed7c-cc37-4b66-a3ad-41fd80ac8e31"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss value: 5.0\n","- Gradient stored in x.grad: tensor([ 4., -2.])\n","- New gradient after second backward: tensor([3., 3.])\n"]}],"source":["x = torch.tensor([2.0, -1.0], requires_grad=True)\n","\n","y = (x ** 2).sum()\n","print('Loss value:', y.item())\n","\n","y.backward()\n","print('- Gradient stored in x.grad:', x.grad)  # x.grad returns the derivative of y (because we called y.backward()) with respect to x\n","# Since y = x[0] ** 2 + x[1] ** 2\n","# x.grad should be tensor([2 * x[0], 2 * x[1]])\n","# which is tensor([4, -2])\n","\n","x.grad.zero_()  # Important to reset the gradient\n","z = (3 * x).sum()\n","z.backward()\n","print('- New gradient after second backward:', x.grad)  # x.grad returns the derivative of z (because we called z.backward()) with respect to x\n","# Here y = 3 * x[0] + 3 * x[1]\n","# x.grad should be tensor([3, 3])"]},{"cell_type":"markdown","id":"09646b49","metadata":{"id":"09646b49"},"source":["## GPU Support\n","\n","One of PyTorch's strengths is the ability to run the same code on CPUs or GPUs. GPU execution is much faster for large models because thousands of operations can run in parallel. Before moving tensors or models, check whether a CUDA-enabled GPU is available with `torch.cuda.is_available()`. Then create a `torch.device` that points to `\"cuda\"` or falls back to `\"cpu\"`. Moving tensors or modules to the device is explicit, which keeps you aware of where the computation happens."]},{"cell_type":"code","execution_count":null,"id":"6bea3f86","metadata":{"id":"6bea3f86","outputId":"505fa1d8-c722-401d-9577-69fbed6bbb66"},"outputs":[{"name":"stdout","output_type":"stream","text":["- Selected device: cpu\n","- Default device: cpu\n","- After move: cpu\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('- Selected device:', device)\n","\n","data = torch.arange(5)\n","print('- Default device:', data.device)\n","\n","data_on_device = data.to(device)\n","print('- After move:', data_on_device.device)"]},{"cell_type":"markdown","id":"f2f33026","metadata":{"id":"f2f33026"},"source":["Using a GPU means every tensor that interacts in an operation must live on the same device. Mixing CPU and GPU tensors raises an error because PyTorch cannot implicitly copy data for you. When you want to visualize or convert a GPU tensor to a NumPy array, first move it to the CPU using .cpu(). If the tensor requires gradients, call .detach() beforehand to remove it from the computation graph. The .detach() method returns a new tensor that shares the same data but is no longer tracked by PyTorch’s autograd system."]},{"cell_type":"markdown","id":"e468ce2aaab3cdbe","metadata":{"id":"e468ce2aaab3cdbe"},"source":["## Models\n","\n","Models in PyTorch are subclasses of `torch.nn.Module`. A module bundles parameters, buffers, and the computations that produce outputs. You can assemble models from prebuilt layers found in `torch.nn` or write your own subclass by defining `__init__` and `forward`. Pretrained models from libraries such as `torchvision` or `torch.hub` are also `nn.Module` instances, so the usage pattern is the same: create or load the module, send inputs through it, and optimise its parameters.\n","\n","Common building blocks include:\n","\n","- `nn.Linear(in_features, out_features)`: affine transformation that multiplies inputs by a weight matrix and adds a bias term.\n","- `nn.ReLU()`, `nn.Sigmoid()`, `nn.Softmax(dim)`: activation layers that apply nonlinear functions elementwise (or across a dimension for `Softmax`). You can also call functional counterparts such as `torch.nn.functional.relu` if you prefer not to instantiate modules.\n","- `nn.Dropout(p)` and `nn.BatchNorm1d(num_features)`: regularisation layers that behave differently during training and evaluation.\n","\n","When subclassing `nn.Module`, implement:\n","\n","- `__init__(self)`: define submodules or parameters and register them as attributes. Calling `super().__init__()` first ensures PyTorch tracks them.\n","- `forward(self, x)`: describe the computation performed at every call. This method receives input tensors, applies submodules or operations, and returns outputs. You normally avoid heavy side effects here because `forward` runs during every training and evaluation step.\n"]},{"cell_type":"code","execution_count":null,"id":"ebfc5ff4","metadata":{"id":"ebfc5ff4","outputId":"4b348986-bd1a-4cc8-e234-1b39a5048543"},"outputs":[{"name":"stdout","output_type":"stream","text":["- Sequential model output: tensor([[-0.1587],\n","        [-0.1259]], grad_fn=<AddmmBackward0>)\n","- Custom model output: tensor([[-0.2893],\n","        [-0.3136]], grad_fn=<AddmmBackward0>)\n"]}],"source":["import torch.nn as nn\n","\n","prebuilt_mlp = nn.Sequential(\n","    nn.Linear(4, 8),\n","    nn.ReLU(),\n","    nn.Linear(8, 1)\n",")\n","# nn.Sequential chains multiple nn.Module layers together. The order they are listed determines the computation order.\n","# In our prebuilt_mlp, the data first traverses the nn.Linear(4, 8) layer, then the nn.ReLU() and finally the nn.Linear(8, 1)\n","\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.hidden = nn.Linear(4, 8)\n","        self.activation = nn.ReLU()\n","        self.output = nn.Linear(8, 1)\n","\n","    def forward(self, x):\n","        x = self.activation(self.hidden(x))\n","        return self.output(x)\n","\n","custom_model = MLP()\n","\n","sample_input = torch.rand(2, 4)\n","print('- Sequential model output:', prebuilt_mlp(sample_input))\n","print('- Custom model output:', custom_model(sample_input))"]},{"cell_type":"markdown","id":"cc68269b","metadata":{"id":"cc68269b"},"source":["### Parameters\n","\n","Every learnable weight inside a module is stored as an instance of `torch.nn.parameter.Parameter`. Modules register parameters automatically when you assign `nn.Module` layers inside `__init__`, but you can also create standalone parameters with `nn.Parameter(tensor)`.\n","\n","Helpful utilities:\n","\n","- Count parameters with `sum(p.numel() for p in model.parameters())` or inspect only trainable ones by adding `if p.requires_grad`.\n","- Custom initialisation can be done with functions from `torch.nn.init`, e.g. `nn.init.xavier_uniform_(layer.weight)` or by manipulating `parameter.data` directly (inside a `torch.no_grad()` block).\n","- `model.named_parameters()` yields `(name, parameter)` pairs, which is useful for logging or applying different learning rates.\n"]},{"cell_type":"code","execution_count":null,"id":"eb030be3","metadata":{"id":"eb030be3","outputId":"05c65a80-5ef8-4404-8d78-6f6760e064ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Trainable parameters of our previously created custom_model: 49\n","hidden.weight: shape=(8, 4), requires_grad=True\n","hidden.bias: shape=(8,), requires_grad=True\n","output.weight: shape=(1, 8), requires_grad=True\n","output.bias: shape=(1,), requires_grad=True\n"]}],"source":["total_params = sum(p.numel() for p in custom_model.parameters() if p.requires_grad)\n","print('Trainable parameters of our previously created custom_model:', total_params)\n","\n","for name, param in custom_model.named_parameters():\n","    print(f'{name}: shape={tuple(param.shape)}, requires_grad={param.requires_grad}')\n"]},{"cell_type":"markdown","id":"50ec0b90727571f5","metadata":{"id":"50ec0b90727571f5"},"source":["## Data Manipulation\n","\n","Training rarely uses raw tensors directly. The `torch.utils.data.TensorDataset` abstraction lets you describe how to load a single sample (`__getitem__`) and how many samples you have (`__len__`). The `DataLoader` wraps a dataset to create batches, optionally shuffles the order, and can load data in parallel. Batching is essential because it keeps memory usage under control while still providing stable gradient estimates."]},{"cell_type":"code","execution_count":null,"id":"f4a33e4284fad2bd","metadata":{"id":"f4a33e4284fad2bd","outputId":"334f0389-2fd0-4ae7-d86b-0b6450eebf15"},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch: 0\n","Batch inputs:\n"," tensor([[-0.6364],\n","        [-0.2727],\n","        [ 0.0909],\n","        [-0.0909]])\n","Batch targets:\n"," tensor([[0.4050],\n","        [0.0744],\n","        [0.0083],\n","        [0.0083]])\n","Batch: 1\n","Batch inputs:\n"," tensor([[ 1.0000],\n","        [ 0.8182],\n","        [-1.0000],\n","        [-0.8182]])\n","Batch targets:\n"," tensor([[1.0000],\n","        [0.6694],\n","        [1.0000],\n","        [0.6694]])\n","Batch: 2\n","Batch inputs:\n"," tensor([[ 0.6364],\n","        [ 0.4545],\n","        [ 0.2727],\n","        [-0.4545]])\n","Batch targets:\n"," tensor([[0.4050],\n","        [0.2066],\n","        [0.0744],\n","        [0.2066]])\n"]}],"source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","# Generation of example inputs and targets\n","inputs = torch.linspace(-1, 1, steps=12).unsqueeze(1)\n","targets = inputs.pow(2)\n","\n","# Initialize TensorDataset and DataLoader\n","dataset = TensorDataset(inputs, targets)\n","loader = DataLoader(dataset, batch_size=4, shuffle=True)\n","\n","# You can access each batch of data iteratively\n","batch = 0\n","for batch_inputs, batch_targets in loader:\n","    print('Batch:', batch)\n","    print('Batch inputs:\\n', batch_inputs)\n","    print('Batch targets:\\n', batch_targets)\n","    batch += 1"]},{"cell_type":"markdown","id":"772ea2bfc1282fb5","metadata":{"id":"772ea2bfc1282fb5"},"source":["## Optimization\n","\n","Training a model is an iterative optimisation process. For each batch you:\n","\n","1. Load a batch from the `DataLoader`.\n","2. Run the model to obtain predictions.\n","3. Evaluate a loss function that compares predictions with targets.\n","4. Call `loss.backward()` to compute gradients.\n","5. Update the parameters with an optimiser such as SGD or Adam.\n","\n","### Loss Modules\n","\n","Loss modules in `torch.nn` wrap common objective functions (`nn.MSELoss`, `nn.CrossEntropyLoss`, etc.). They usually accept predictions and targets and return a scalar tensor with `requires_grad=True`, ready for backpropagation.\n","\n","### Optimizers\n","\n","Optimisers in `torch.optim` (e.g. `SGD`, `Adam`, `RMSprop`) manage how parameters are updated. They expect the model's parameters and hyperparameters like the learning rate. The standard pattern is `optimizer.zero_grad()`, `loss.backward()`, and `optimizer.step()` every iteration. All in all, the optimizer updates the parameters of the model in order to minimize the loss."]},{"cell_type":"code","execution_count":null,"id":"c2286884","metadata":{"id":"c2286884","outputId":"e50bc00e-0733-432a-ec78-1ac3529e9da3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initial loss: 29.755882263183594\n","Initial parameters: tensor([[-0.5987]]) tensor([0.0028])\n","Updated loss: 8.413677215576172\n","Updated parameters: tensor([[0.8003]]) tensor([0.9220])\n"]}],"source":["model = torch.nn.Linear(1, 1)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n","loss_fn = torch.nn.MSELoss()\n","\n","# Generation of data + labels\n","x_batch = torch.tensor([[0.0], [1.0], [2.0]])\n","y_batch = 3 * x_batch + 1\n","\n","predictions = model(x_batch)\n","loss = loss_fn(predictions, y_batch)\n","print('Initial loss:', loss.item())\n","print('Initial parameters:', model.weight.data, model.bias.data)\n","\n","optimizer.zero_grad()\n","loss.backward()\n","optimizer.step()\n","\n","updated_predictions = model(x_batch)\n","updated_loss = loss_fn(updated_predictions, y_batch)\n","print('Updated loss:', updated_loss.item())\n","print('Updated parameters:', model.weight.data, model.bias.data)"]},{"cell_type":"markdown","id":"4a17c180","metadata":{"id":"4a17c180"},"source":["## Training a Model\n","\n","A full training loop repeats the optimisation steps for many epochs (passes over the dataset). During training you may log metrics, adjust the learning rate, or validate on a separate dataset. Switching between `model.train()` and `model.eval()` toggles behaviours such as dropout or batch-normalisation, so remember to call `model.train()` before the training loop."]},{"cell_type":"code","execution_count":null,"id":"83f3ab80","metadata":{"id":"83f3ab80","outputId":"abd28f12-f156-4d08-ddd0-b4ef4ec5c4b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 10 - average loss: 0.0129\n","Epoch 20 - average loss: 0.0120\n","Epoch 30 - average loss: 0.0100\n","Epoch 40 - average loss: 0.0105\n","Epoch 50 - average loss: 0.0101\n","Learned weight: 2.005248546600342\n","Learned bias: 1.025797724723816\n"]}],"source":["from torch.utils.data import DataLoader, TensorDataset\n","\n","torch.manual_seed(0)\n","\n","# Generate data + labels\n","x_values = torch.linspace(-1, 1, steps=100).unsqueeze(1)\n","y_values = 2 * x_values + 1 + 0.1 * torch.randn_like(x_values)\n","#        weight=2    bias=1 + noise\n","\n","# Initialize TensorDataset and DataLoader\n","training_dataset = TensorDataset(x_values, y_values)\n","training_loader = DataLoader(training_dataset, batch_size=16, shuffle=True)\n","\n","# Initialize model, optimizer, loss function and put model in training mode\n","linear_model = torch.nn.Linear(1, 1)\n","optimizer = torch.optim.SGD(linear_model.parameters(), lr=0.2)\n","loss_fn = torch.nn.MSELoss()\n","linear_model.train()\n","\n","# Training loop\n","for epoch in range(1, 51):  # Use all the data for gradient descent 50 times\n","    epoch_loss = 0.0\n","    for batch_x, batch_y in training_loader:  # For every batch of data\n","        optimizer.zero_grad()\n","        preds = linear_model(batch_x)\n","        loss = loss_fn(preds, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","    if epoch % 10 == 0:  # Print updates every 10 epochs\n","        avg_loss = epoch_loss / len(training_loader)\n","        print(f'Epoch {epoch:02d} - average loss: {avg_loss:.4f}')\n","\n","print('Learned weight:', linear_model.weight.item())\n","print('Learned bias:', linear_model.bias.item())\n","trained_model = linear_model"]},{"cell_type":"markdown","id":"10b795ae","metadata":{"id":"10b795ae"},"source":["### Saving and Loading a Model\n","\n","After training you usually want to persist the model's learned parameters. The recommended approach is to save the `state_dict`, a simple mapping from parameter names to tensors. Saving the full module with `torch.save(model.state_dict(), path)` keeps files lightweight and device agnostic. Later, create the same model architecture, load the saved dictionary with `load_state_dict`, and optionally move it to the desired device."]},{"cell_type":"code","execution_count":null,"id":"7111eda2","metadata":{"id":"7111eda2","outputId":"80fdfe1d-5c0c-43e9-9810-9f6a9c2a9cb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["State dict saved to linear_regression.pth\n","- Original model prediction: 2.0284218788146973\n","- Reloaded model prediction: 2.0284218788146973\n"]}],"source":["model_path = 'linear_regression.pth'\n","torch.save(trained_model.state_dict(), model_path)\n","print(f'State dict saved to {model_path}')\n","\n","# Recreate model structure\n","reloaded_model = torch.nn.Linear(1, 1)\n","# Load saved parameters\n","reloaded_model.load_state_dict(torch.load(model_path))\n","# Put model in evaluation mode\n","reloaded_model.eval()\n","\n","sample_input = torch.tensor([[0.5]])\n","with torch.no_grad():\n","    original_pred = trained_model(sample_input)\n","    reloaded_pred = reloaded_model(sample_input)\n","print('- Original model prediction:', original_pred.item())\n","print('- Reloaded model prediction:', reloaded_pred.item())"]},{"cell_type":"markdown","id":"31dd2687","metadata":{"id":"31dd2687"},"source":["### Evaluating a Model\n","\n","Evaluation mode disables training-specific layers and stops tracking gradients, which makes inference faster and safer. Wrap evaluation code in `with torch.no_grad():` to skip autograd bookkeeping. Compute metrics such as accuracy, mean absolute error, or F1 score to understand how well the model generalises."]},{"cell_type":"code","execution_count":null,"id":"2100caa6","metadata":{"id":"2100caa6","outputId":"0b8b7165-af21-4672-ff4d-850b14f55a2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean squared error on training data: 0.0110\n","Example predictions: [0.6247479915618896, 1.025797724723816, 2.6299965381622314]\n"]}],"source":["trained_model.eval()\n","\n","with torch.no_grad():\n","    predictions = trained_model(x_values)\n","    mse = torch.mean((predictions - y_values) ** 2)\n","    print(f'Mean squared error on training data: {mse:.4f}')\n","\n","    example_points = torch.tensor([[-0.2], [0.0], [0.8]])\n","    example_preds = trained_model(example_points)\n","print('Example predictions:', example_preds.squeeze().tolist())"]},{"cell_type":"markdown","id":"e50c9b98392b7006","metadata":{"id":"e50c9b98392b7006"},"source":["## Example: simple use case\n","\n","To tie everything together, let's train a tiny neural network to classify 2D points into two classes. We'll generate synthetic data, wrap it in a `DataLoader`, define a model, train it on a chosen device, and measure accuracy. The pattern mirrors what you would do with a real dataset—only the data loader and model complexity grow."]},{"cell_type":"code","execution_count":null,"id":"61b438d8","metadata":{"id":"61b438d8","outputId":"fc25ac22-8ac2-40e0-a183-fcb9341f73d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 05 - loss: 0.2053\n","Epoch 10 - loss: 0.2027\n","Epoch 15 - loss: 0.2074\n","Epoch 20 - loss: 0.1985\n","Accuracy on the generated dataset: 0.915\n","Sample predictions: [1, 1, 0, 0, 0, 1, 0, 1, 1, 1]\n","Sample labels:      [1, 1, 1, 0, 0, 1, 0, 1, 1, 1]\n"]}],"source":["torch.manual_seed(1)\n","\n","num_samples = 200\n","class0 = torch.randn(num_samples, 2) - 1.0\n","class1 = torch.randn(num_samples, 2) + 1.0\n","\n","features = torch.cat([class0, class1], dim=0)\n","labels = torch.cat([torch.zeros(num_samples), torch.ones(num_samples)], dim=0).long()\n","\n","perm = torch.randperm(features.size(0))  # randomise order\n","features = features[perm]\n","labels = labels[perm]\n","\n","dataset = TensorDataset(features, labels)\n","loader = DataLoader(dataset, batch_size=32, shuffle=True)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","classification_model = torch.nn.Sequential(\n","    torch.nn.Linear(2, 16),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(16, 1)\n",").to(device)\n","\n","loss_fn = torch.nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(classification_model.parameters(), lr=0.01)\n","\n","# Training loop\n","classification_model.train()\n","for epoch in range(1, 21):\n","    epoch_loss = 0.0\n","    for batch_features, batch_labels in loader:\n","        batch_features = batch_features.to(device)\n","        batch_labels = batch_labels.to(device).float()\n","\n","        optimizer.zero_grad()\n","        logits = classification_model(batch_features).squeeze(1)\n","        loss = loss_fn(logits, batch_labels)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","    if epoch % 5 == 0:\n","        print(f'Epoch {epoch:02d} - loss: {epoch_loss / len(loader):.4f}')\n","\n","# Evaluation on the whole dataset\n","classification_model.eval()\n","with torch.no_grad():\n","    logits = classification_model(features.to(device)).squeeze(1)\n","    predictions = (torch.sigmoid(logits) > 0.5).long().cpu()\n","    accuracy = (predictions == labels).float().mean().item()\n","\n","print(f'Accuracy on the generated dataset: {accuracy:.3f}')\n","print('Sample predictions:', predictions[:10].tolist())\n","print('Sample labels:     ', labels[:10].tolist())"]},{"cell_type":"markdown","id":"096fc796","metadata":{"id":"096fc796"},"source":["## Conclusion\n","\n","You now know how to create and manipulate tensors, build models, prepare data loaders, train with optimisation loops, leverage GPUs, save checkpoints, and evaluate results. PyTorch's dynamic graph and clean API make experimentation approachable, so keep iterating on these building blocks with your own datasets and architectures. Whenever you need deeper details, refer to the official [PyTorch documentation](https://pytorch.org/docs/stable/index.html)."]}],"metadata":{"kernelspec":{"display_name":"Python (.venv)","language":"python","name":".venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}