{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# navigating your repository\n",
    "path = Path(os.getcwd())\n",
    "PROJECT_ROOT = path.parent.absolute()\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, r\"training-data\\data_train_track2_refit.csv\")\n",
    "PLOTS_DIR = os.path.join(PROJECT_ROOT, r\"main\\plots\")\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Using project root: {PROJECT_ROOT}\")\n",
    "print(f\"Train data path: {DATA_PATH}\")\n",
    "print(f\"Plots will be saved to: {PLOTS_DIR}\")\n",
    "\n",
    "# Load training data (day-first dates)\n",
    "df = pd.read_csv(DATA_PATH, header=0 ,sep=';')\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
    "\n",
    "\n",
    "# Keep Date as first column\n",
    "df = df[['date'] + [c for c in df.columns if c != 'date']]\n",
    "feature_cols = [c for c in df.columns if c != 'date']\n",
    "\n",
    "df[\"value\"] = df[\"value\"].str.replace(\",\", \".\").astype(float)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# 1) Linear time index (trend)\n",
    "df[\"time_idx\"] = (df[\"date\"] - df[\"date\"].min()).dt.days\n",
    "\n",
    "# 2) Day-of-year cyclic features (seasonality)\n",
    "df[\"doy\"] = df[\"date\"].dt.dayofyear\n",
    "\n",
    "df[\"doy_sin\"] = np.sin(2 * np.pi * df[\"doy\"] / 365.25)\n",
    "df[\"doy_cos\"] = np.cos(2 * np.pi * df[\"doy\"] / 365.25)\n",
    "\n",
    "print(df.head())\n",
    "print(f\"Rows: {len(df)}\")\n",
    "print(f\"Date range: {df['date'].min().date()} → {df['date'].max().date()}\")\n",
    "print(f\"Number of surface points: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split df by date order so test = 20% most recent dates\n",
    "test_size = 0.2  # 20% most recent rows for test\n",
    "\n",
    "split_idx = int(len(df) * (1 - test_size))\n",
    "\n",
    "train_df = df.iloc[:split_idx].copy()  # older data\n",
    "test_df  = df.iloc[split_idx:].copy() \n",
    "\n",
    "print(f\"Train date range: {train_df['date'].min()} → {train_df['date'].max()}\")\n",
    "print(f\"Test date range:  {test_df['date'].min()} → {test_df['date'].max()}\")\n",
    "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a865d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df[feature_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "TARGET_COL = \"value\"\n",
    "DATE_COL = \"date\"\n",
    "\n",
    "# All feature columns except raw date + target\n",
    "feature_cols = [\n",
    "    c for c in df.columns \n",
    "    if c not in [TARGET_COL, DATE_COL, \"doy\"]  # we keep sin/cos, drop raw doy\n",
    "]\n",
    "\n",
    "print(\"Features:\", feature_cols)\n",
    "\n",
    "feature_cols = [\"tenor\", \"maturity\", \"time_idx\", \"doy_sin\", \"doy_cos\"]\n",
    "TARGET_COL = \"value\"   # or whatever your target is called\n",
    "\n",
    "# 1. Numpy arrays (float32 initial cast)\n",
    "X_train = train_df[feature_cols].to_numpy(dtype=np.float32)\n",
    "y_train = train_df[TARGET_COL].to_numpy(dtype=np.float32)\n",
    "X_test  = test_df[feature_cols].to_numpy(dtype=np.float32)\n",
    "y_test  = test_df[TARGET_COL].to_numpy(dtype=np.float32)\n",
    "\n",
    "# 2. Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test  = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "print(\"X_train type:\", type(X_train), \"dtype:\", X_train.dtype)\n",
    "\n",
    "# 3. Tensors (use from_numpy, no dtype confusion)\n",
    "X_train_t = torch.from_numpy(X_train)                   # torch.float32\n",
    "X_test_t  = torch.from_numpy(X_test)\n",
    "\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "y_test_t  = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa68ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.datasets import mnist_digits\n",
    "\n",
    "train_features, train_labels, train_metadata = mnist_digits.get_data_train_percevalquest()\n",
    "test_features, test_labels, test_metadata = mnist_digits.get_data_test_percevalquest()\n",
    "\n",
    "# Flatten the images from (N, 28, 28) to (N, 784)\n",
    "train_features = train_features.reshape(train_features.shape[0], -1)\n",
    "test_features = test_features.reshape(test_features.shape[0], -1)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.FloatTensor(train_features)\n",
    "y_train = torch.LongTensor(train_labels)\n",
    "X_test = torch.FloatTensor(test_features)\n",
    "y_test = torch.LongTensor(test_labels)\n",
    "\n",
    "print(f\"Dataset loaded: {len(X_train)} training samples, {len(X_test)} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c7cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform, struct, torch, numpy as np\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Bits:\", struct.calcsize(\"P\") * 8)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"numpy:\", np.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
