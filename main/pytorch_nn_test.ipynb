{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b54b5cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project root: c:\\Workspace\\quantum repo\\MilaHackFest\n",
      "Train data path: c:\\Workspace\\quantum repo\\MilaHackFest\\training-data\\data_train_track2_refit.csv\n",
      "Plots will be saved to: c:\\Workspace\\quantum repo\\MilaHackFest\\main\\plots\n",
      "        date  tenor   maturity     value  time_idx  doy   doy_sin   doy_cos\n",
      "0 2050-01-01      1   0.083333  0.028565         0    1  0.017202  0.999852\n",
      "1 2050-01-01      9  10.000000  0.253176         0    1  0.017202  0.999852\n",
      "2 2050-01-01      3   0.250000  0.070905         0    1  0.017202  0.999852\n",
      "3 2050-01-01     15   3.000000  0.183596         0    1  0.017202  0.999852\n",
      "4 2050-01-01      5   1.500000  0.162868         0    1  0.017202  0.999852\n",
      "Rows: 110656\n",
      "Date range: 2050-01-01 → 2051-12-23\n",
      "Number of surface points: 3\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# navigating your repository\n",
    "path = Path(os.getcwd())\n",
    "PROJECT_ROOT = path.parent.absolute()\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, r\"training-data\\data_train_track2_refit.csv\")\n",
    "PLOTS_DIR = os.path.join(PROJECT_ROOT, r\"main\\plots\")\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Using project root: {PROJECT_ROOT}\")\n",
    "print(f\"Train data path: {DATA_PATH}\")\n",
    "print(f\"Plots will be saved to: {PLOTS_DIR}\")\n",
    "\n",
    "# Load training data (day-first dates)\n",
    "df = pd.read_csv(DATA_PATH, header=0 ,sep=';')\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
    "\n",
    "\n",
    "# Keep Date as first column\n",
    "df = df[['date'] + [c for c in df.columns if c != 'date']]\n",
    "feature_cols = [c for c in df.columns if c != 'date']\n",
    "\n",
    "df[\"value\"] = df[\"value\"].str.replace(\",\", \".\").astype(float)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# 1) Linear time index (trend)\n",
    "df[\"time_idx\"] = (df[\"date\"] - df[\"date\"].min()).dt.days\n",
    "\n",
    "# 2) Day-of-year cyclic features (seasonality)\n",
    "df[\"doy\"] = df[\"date\"].dt.dayofyear\n",
    "\n",
    "df[\"doy_sin\"] = np.sin(2 * np.pi * df[\"doy\"] / 365.25)\n",
    "df[\"doy_cos\"] = np.cos(2 * np.pi * df[\"doy\"] / 365.25)\n",
    "\n",
    "print(df.head())\n",
    "print(f\"Rows: {len(df)}\")\n",
    "print(f\"Date range: {df['date'].min().date()} → {df['date'].max().date()}\")\n",
    "print(f\"Number of surface points: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbdf541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train date range: 2050-01-01 00:00:00 → 2051-08-01 00:00:00\n",
      "Test date range:  2051-08-01 00:00:00 → 2051-12-23 00:00:00\n",
      "Train rows: 88524, Test rows: 22132\n"
     ]
    }
   ],
   "source": [
    "# split df by date order so test = 20% most recent dates\n",
    "test_size = 0.2  # 20% most recent rows for test\n",
    "\n",
    "split_idx = int(len(df) * (1 - test_size))\n",
    "\n",
    "train_df = df.iloc[:split_idx].copy()  # older data\n",
    "test_df  = df.iloc[split_idx:].copy() \n",
    "\n",
    "print(f\"Train date range: {train_df['date'].min()} → {train_df['date'].max()}\")\n",
    "print(f\"Test date range:  {test_df['date'].min()} → {test_df['date'].max()}\")\n",
    "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5915fd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['tenor', 'maturity', 'time_idx', 'doy_sin', 'doy_cos']\n",
      "X_train type: <class 'numpy.ndarray'> dtype: float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "TARGET_COL = \"value\"\n",
    "DATE_COL = \"date\"\n",
    "\n",
    "# All feature columns except raw date + target\n",
    "feature_cols = [\n",
    "    c for c in df.columns \n",
    "    if c not in [TARGET_COL, DATE_COL, \"doy\"]  # we keep sin/cos, drop raw doy\n",
    "]\n",
    "\n",
    "print(\"Features:\", feature_cols)\n",
    "\n",
    "feature_cols = [\"tenor\", \"maturity\", \"time_idx\", \"doy_sin\", \"doy_cos\"]\n",
    "TARGET_COL = \"value\"   # or whatever your target is called\n",
    "\n",
    "# 1. Numpy arrays (float32 initial cast)\n",
    "X_train = train_df[feature_cols].to_numpy(dtype=np.float32)\n",
    "y_train = train_df[TARGET_COL].to_numpy(dtype=np.float32)\n",
    "X_test  = test_df[feature_cols].to_numpy(dtype=np.float32)\n",
    "y_test  = test_df[TARGET_COL].to_numpy(dtype=np.float32)\n",
    "\n",
    "# 2. Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test  = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "print(\"X_train type:\", type(X_train), \"dtype:\", X_train.dtype)\n",
    "\n",
    "# 3. Tensors (use from_numpy, no dtype confusion)\n",
    "X_train_t = torch.from_numpy(X_train)                   # torch.float32\n",
    "X_test_t  = torch.from_numpy(X_test)\n",
    "\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "y_test_t  = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6db1bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import perceval as pcvl\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from merlin import QuantumLayer, LexGrouping\n",
    "from merlin.builder import CircuitBuilder\n",
    "import merlin as ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f59fc633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<merlin.builder.circuit_builder.CircuitBuilder at 0x243de508d90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = CircuitBuilder(n_modes=6)\n",
    "builder.add_entangling_layer(trainable=True, name=\"U1\")\n",
    "builder.add_angle_encoding(modes=[0, 1, 2, 3, 4], name=\"input\")   # map 5 features -> 5 modes\n",
    "builder.add_rotations(trainable=True, name=\"theta\")            # extra expressivity\n",
    "builder.add_superpositions(depth=1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9881bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1008.75\" height=\"406.25\" viewBox=\"-28.5 0 807.0 325.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M27.5,2.5 L122.5,2.5 L122.5,297.5 L27.5,297.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"35\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=input1</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=input2</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=input3</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=input4</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=input5</text>\n",
       "<path d=\"M175,25 L225,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M180,40 L189,40 L203,10 L194,10 L180,40 L189,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"197\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=theta_0</text>\n",
       "<path d=\"M175,75 L225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M180,90 L189,90 L203,60 L194,60 L180,90 L189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=theta_1</text>\n",
       "<path d=\"M175,125 L225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M180,140 L189,140 L203,110 L194,110 L180,140 L189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=theta_2</text>\n",
       "<path d=\"M175,175 L225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M180,190 L189,190 L203,160 L194,160 L180,190 L189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=theta_3</text>\n",
       "<path d=\"M175,225 L225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M180,240 L189,240 L203,210 L194,210 L180,240 L189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=theta_4</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=theta_5</text>\n",
       "<path d=\"M225,25 L253,25 L272,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M278,44 L297,25 L325,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M225,75 L253,75 L272,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M278,56 L297,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M250,43 L300,43 L300,57 L250,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"275\" y=\"85\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"275\" y=\"26\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M250,43 L300,43 L300,47 L250,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M293,50 L303,50 L303,60 L293,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"298\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M225,125.0 L325,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,94 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,125 L353,125 L372,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,106 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,93 L400,93 L400,107 L350,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"135\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"76\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M350,93 L400,93 L400,97 L350,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,100 L403,100 L403,110 L393,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M225,175.0 L425,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M425,125 L453,125 L472,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M478,144 L497,125 L525,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M425,175 L453,175 L472,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M478,156 L497,175 L525,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M450,143 L500,143 L500,157 L450,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"475\" y=\"185\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"475\" y=\"126\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M450,143 L500,143 L500,147 L450,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M493,150 L503,150 L503,160 L493,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"498\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M225,225.0 L525,225.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M525,175 L553,175 L572,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M578,194 L597,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M525,225 L553,225 L572,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M578,206 L597,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M550,193 L600,193 L600,207 L550,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"575\" y=\"235\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"575\" y=\"176\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M550,193 L600,193 L600,197 L550,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M593,200 L603,200 L603,210 L593,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"598\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M175,275.0 L625,275.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"285\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M325,25.0 L725,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M425,75.0 L725,75.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M525,125.0 L725,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175.0 L725,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M725,25.0 L740,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M725,75.0 L740,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M725,125.0 L740,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M725,175.0 L740,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M725,225.0 L740,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M725,275.0 L740,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"750\" y=\"28.0\" font-size=\"7\" text-anchor=\"end\">0</text>\n",
       "<text x=\"750\" y=\"78.0\" font-size=\"7\" text-anchor=\"end\">1</text>\n",
       "<text x=\"750\" y=\"128.0\" font-size=\"7\" text-anchor=\"end\">2</text>\n",
       "<text x=\"750\" y=\"178.0\" font-size=\"7\" text-anchor=\"end\">3</text>\n",
       "<text x=\"750\" y=\"228.0\" font-size=\"7\" text-anchor=\"end\">4</text>\n",
       "<text x=\"750\" y=\"278.0\" font-size=\"7\" text-anchor=\"end\">5</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"7\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"7\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"7\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"7\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"7\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"7\" text-anchor=\"start\">5</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x243de5711b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core = QuantumLayer(\n",
    "    input_size=5,     # number of classical features\n",
    "    builder=builder,\n",
    "    n_photons=3,      # equivalent to input_state = [1,1,1,0,0,0]\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "pcvl.pdisplay(core.circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab9e8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumInterestRateModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        classical_hidden: int = 32,\n",
    "        quantum_input_dim: int = 4,\n",
    "        quantum_n_params: int = 64,\n",
    "        head_hidden: int = 32,\n",
    "        dropout: float = 0.1,\n",
    "        dtype: torch.dtype = torch.float32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) Classical \"pre\" block: map features -> quantum_input_dim\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Linear(input_dim, classical_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(classical_hidden, quantum_input_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 2) Quantum layer from MerLin\n",
    "        #    QuantumLayer.simple builds a ready-to-train photonic circuit\n",
    "        #    with angle encoding + probabilities as outputs. \n",
    "        self.quantum = ML.QuantumLayer.simple(\n",
    "            input_size=quantum_input_dim,\n",
    "            n_params=quantum_n_params,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "\n",
    "        # quantum layer has an attribute output_size (length of probability vector) \n",
    "        q_out_dim = self.quantum.output_size\n",
    "\n",
    "        # 3) Classical \"head\" block: quantum output -> scalar rate\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(q_out_dim, head_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(head_hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch_size, input_dim)\n",
    "        x = self.pre(x)          # -> (batch_size, quantum_input_dim)\n",
    "        x = self.quantum(x)      # -> (batch_size, q_out_dim) probabilities / logits\n",
    "        x = self.head(x)         # -> (batch_size, 1) regression output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f297d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aseri\\AppData\\Local\\Temp\\ipykernel_14112\\200941663.py:26: RuntimeWarning: Entangling layer introduces 90 trainable parameters, exceeding the requested budget of 64. The simple layer will expose 90 trainable parameters.\n",
      "  self.quantum = ML.QuantumLayer.simple(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | train MSE: 0.003006 | test MSE: 0.006560\n",
      "Epoch   2 | train MSE: 0.000820 | test MSE: 0.005075\n",
      "Epoch   3 | train MSE: 0.000648 | test MSE: 0.004064\n",
      "Epoch   4 | train MSE: 0.000565 | test MSE: 0.003597\n",
      "Epoch   5 | train MSE: 0.000540 | test MSE: 0.002583\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "test_ds  = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "input_dim = X_train_t.shape[1]\n",
    "\n",
    "model = QuantumInterestRateModel(\n",
    "    input_dim=input_dim,\n",
    "    classical_hidden=32,\n",
    "    quantum_input_dim=4,   # must match pre block output\n",
    "    quantum_n_params=64,\n",
    "    head_hidden=32,\n",
    "    dropout=0.1,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        preds = model(X_batch)\n",
    "        loss = loss_fn(preds, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    train_mse = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            preds = model(X_batch)\n",
    "            loss = loss_fn(preds, y_batch)\n",
    "            test_loss += loss.item() * X_batch.size(0)\n",
    "        test_mse = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:3d} | train MSE: {train_mse:.6f} | test MSE: {test_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54dd4551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rate: 0.1542634516954422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aseri\\AppData\\Local\\Temp\\ipykernel_14112\\293527292.py:4: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  new_df[\"date\"] = pd.to_datetime(new_df[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "def predict_single(model, scaler, df_train, new_row):\n",
    "    # new_row: dict with raw values, including \"date\"\n",
    "    new_df = pd.DataFrame([new_row])\n",
    "    new_df[\"date\"] = pd.to_datetime(new_df[\"date\"])\n",
    "\n",
    "    # recreate engineered features (time_idx must use the same reference!)\n",
    "    new_df[\"time_idx\"] = (new_df[\"date\"] - df_train[\"date\"].min()).dt.days\n",
    "    new_df[\"doy\"] = new_df[\"date\"].dt.dayofyear\n",
    "    new_df[\"doy_sin\"] = np.sin(2*np.pi*new_df[\"doy\"]/365.25)\n",
    "    new_df[\"doy_cos\"] = np.cos(2*np.pi*new_df[\"doy\"]/365.25)\n",
    "\n",
    "    feature_cols = [\"tenor\", \"maturity\", \"time_idx\", \"doy_sin\", \"doy_cos\"]\n",
    "\n",
    "    # scale features\n",
    "    X_raw = new_df[feature_cols].to_numpy(dtype=np.float32)\n",
    "    X_scaled = scaler.transform(X_raw).astype(np.float32)\n",
    "    X_t = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "\n",
    "    # model prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_t).item()\n",
    "\n",
    "    return pred\n",
    "\n",
    "prediction = predict_single(\n",
    "    model,\n",
    "    scaler,\n",
    "    df,    # full training df, needed for time_idx reference\n",
    "    {\n",
    "        \"date\": \"24/12/2051\",\n",
    "        \"tenor\": 1,\n",
    "        \"maturity\": 0.0833333333333333\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Predicted rate:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
